{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tsfresh.examples.robot_execution_failures import download_robot_execution_failures, load_robot_execution_failures\n",
    "from tsfresh.feature_extraction import extract_features, extract_features_on_sub_features\n",
    "from tsfresh.feature_selection import select_features\n",
    "from tsfresh.feature_extraction.settings import MinimalFCParameters \n",
    "\n",
    "from tsfresh.feature_extraction.gen_features_dicts_function import derive_features_dictionaries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  time  F_x  F_y  F_z  T_x  T_y  T_z\n",
      "0   1     0   -1   -1   63   -3   -1    0\n",
      "1   1     1    0    0   62   -3   -1    0\n",
      "2   1     2   -1   -1   61   -3    0    0\n",
      "3   1     3   -1   -1   63   -2   -1    0\n",
      "4   1     4   -1   -1   63   -3   -1    0\n"
     ]
    }
   ],
   "source": [
    "download_robot_execution_failures()\n",
    "timeseries, y = load_robot_execution_failures()\n",
    "print(timeseries.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from the Time Series\n",
    "Let us start by demonstrating how a simple set of time series features (mean, median, max, variance, ...) are calculated from an example time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/scott/miniconda3/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "extracted_features = extract_features(timeseries, column_id=\"id\", column_sort=\"time\")\n",
    "print(extracted_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to extract features from an existing feature matrix\n",
    "Should we find that these features themselves are not sufficiently informative for whatever reason, we can repeat the same feature extraction process using the  `extract_features_on_sub_features` function.\n",
    "\n",
    "In principle this works as such:\n",
    "\n",
    "1. The input time *X* series is windowed and the chosen set of N features are extracted. This returns a new matrix *M* where each column represents a particular **feature time series**.\n",
    "\n",
    "2. For each feature in the resulting output, step 1 is repeated and for the chosen feature time series. Each new column generated can be referred to as a **sub-feature** or  **feature-dynamic**\n",
    "    \n",
    "3. Repeat for each column in *M*.\n",
    "\n",
    "## Differences to `extract_features`\n",
    "`extract_features_on_sub_features` shares most of the same parameters as `extract_features`\n",
    "\n",
    "**Note:** that the resulting output of this operation can lead to an exponential number of columns generated. For instance if the input has 1 time series and we extract N features...\n",
    "\n",
    "Below the algorithm is demonstrated on the same robot executaion failures dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!DIAGRAM FROM P4P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 68.36it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:01<00:00, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   F_x||length__sum_values  F_x||length__median  F_x||length__mean  \\\n",
      "1                     15.0                  7.5                7.5   \n",
      "2                     15.0                  7.5                7.5   \n",
      "3                     15.0                  7.5                7.5   \n",
      "4                     15.0                  7.5                7.5   \n",
      "5                     15.0                  7.5                7.5   \n",
      "\n",
      "   F_x||length__length  F_x||length__standard_deviation  \\\n",
      "1                  2.0                              3.5   \n",
      "2                  2.0                              3.5   \n",
      "3                  2.0                              3.5   \n",
      "4                  2.0                              3.5   \n",
      "5                  2.0                              3.5   \n",
      "\n",
      "   F_x||length__variance  F_x||length__maximum  F_x||length__minimum  \\\n",
      "1                  12.25                  11.0                   4.0   \n",
      "2                  12.25                  11.0                   4.0   \n",
      "3                  12.25                  11.0                   4.0   \n",
      "4                  12.25                  11.0                   4.0   \n",
      "5                  12.25                  11.0                   4.0   \n",
      "\n",
      "   F_x||maximum__sum_values  F_x||maximum__median  ...  \\\n",
      "1                      -1.0                  -0.5  ...   \n",
      "2                       0.0                   0.0  ...   \n",
      "3                       0.0                   0.0  ...   \n",
      "4                       1.0                   0.5  ...   \n",
      "5                       1.0                   0.5  ...   \n",
      "\n",
      "   T_z||sum_values__maximum  T_z||sum_values__minimum  \\\n",
      "1                       0.0                       0.0   \n",
      "2                      -1.0                      -3.0   \n",
      "3                      -2.0                      -2.0   \n",
      "4                      -2.0                      -3.0   \n",
      "5                       1.0                      -3.0   \n",
      "\n",
      "   T_z||variance__sum_values  T_z||variance__median  T_z||variance__mean  \\\n",
      "1                   0.000000               0.000000             0.000000   \n",
      "2                   0.385847               0.192924             0.192924   \n",
      "3                   0.398760               0.199380             0.199380   \n",
      "4                   0.630165               0.315083             0.315083   \n",
      "5                   0.451963               0.225981             0.225981   \n",
      "\n",
      "   T_z||variance__length  T_z||variance__standard_deviation  \\\n",
      "1                    2.0                           0.000000   \n",
      "2                    2.0                           0.005424   \n",
      "3                    2.0                           0.050620   \n",
      "4                    2.0                           0.065083   \n",
      "5                    2.0                           0.038481   \n",
      "\n",
      "   T_z||variance__variance  T_z||variance__maximum  T_z||variance__minimum  \n",
      "1                 0.000000                0.000000                 0.00000  \n",
      "2                 0.000029                0.198347                 0.18750  \n",
      "3                 0.002562                0.250000                 0.14876  \n",
      "4                 0.004236                0.380165                 0.25000  \n",
      "5                 0.001481                0.264463                 0.18750  \n",
      "\n",
      "[5 rows x 384 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_sub_features = extract_features_on_sub_features(timeseries_container=timeseries,\n",
    "                                    sub_feature_split=11,  # window size\n",
    "                                    column_id=\"id\",\n",
    "                                    column_sort=\"time\",\n",
    "                                    sub_default_fc_parameters=MinimalFCParameters(),\n",
    "                                    ##TODO: check if one of these isnt specified use the other\n",
    "                                    default_fc_parameters=MinimalFCParameters())\n",
    "print(extracted_sub_features.head())                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the results\n",
    "\n",
    "As can be seen, running `extract_features_on_sub_features` results in significantly more columns\n",
    "\n",
    "## Decomposing the column names\n",
    "`\"F_x||length__sum_values\"`\n",
    "\n",
    "This is demonstrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set f features calculated on the original time series:\n",
      "\n",
      "{\n",
      "    \"F_x\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## Take a subset of the columns to demonstrate (reduce size of output)\n",
    "sub_feature_names = extracted_sub_features.columns.tolist()[:120]\n",
    "f,ff = derive_features_dictionaries(sub_feature_names)\n",
    "\n",
    "print(\"The set f features calculated on the original time series:\\n\")\n",
    "#[print(f[k],\"\\n\") for k in f.keys()]\n",
    "print(json.dumps(f,sort_keys=True, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**talk about how to interpret this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"F_x||length\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||maximum\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||mean\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||median\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||minimum\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||standard_deviation\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||sum_values\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_x||variance\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||length\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||maximum\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||mean\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||median\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||minimum\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||standard_deviation\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    },\n",
      "    \"F_y||sum_values\": {\n",
      "        \"length\": null,\n",
      "        \"maximum\": null,\n",
      "        \"mean\": null,\n",
      "        \"median\": null,\n",
      "        \"minimum\": null,\n",
      "        \"standard_deviation\": null,\n",
      "        \"sum_values\": null,\n",
      "        \"variance\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#print(\"\\nThe set of feature-dynamics/sub-features generate on the feature time-series\",ff, sep=\"\\n\")\n",
    "print(json.dumps(ff,sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the most relevant time Series features from both of these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   T_y__standard_deviation  T_y__variance  F_z__standard_deviation  \\\n",
      "1                 0.471405       0.222222                 1.203698   \n",
      "2                 2.054805       4.222222                 4.333846   \n",
      "3                 1.768867       3.128889                 4.616877   \n",
      "4                 2.669998       7.128889                 3.833188   \n",
      "5                 2.039608       4.160000                 4.841487   \n",
      "\n",
      "   F_z__variance  F_x__standard_deviation  F_x__variance  \\\n",
      "1       1.448889                 0.249444       0.062222   \n",
      "2      18.782222                 0.956847       0.915556   \n",
      "3      21.315556                 0.596285       0.355556   \n",
      "4      14.693333                 0.952190       0.906667   \n",
      "5      23.440000                 0.879394       0.773333   \n",
      "\n",
      "   T_x__standard_deviation  T_x__variance  F_y__variance  \\\n",
      "1                 0.339935       0.115556       0.115556   \n",
      "2                 3.422799      11.715556       4.622222   \n",
      "3                 2.633122       6.933333       2.382222   \n",
      "4                 3.525148      12.426667       3.982222   \n",
      "5                 2.756810       7.600000       2.995556   \n",
      "\n",
      "   F_y__standard_deviation  ...  F_z__mean  F_z__median  F_y__maximum  \\\n",
      "1                 0.339935  ...  62.533333         63.0           0.0   \n",
      "2                 2.149935  ...  62.133333         63.0           3.0   \n",
      "3                 1.543445  ...  61.133333         61.0           2.0   \n",
      "4                 1.995551  ...  62.200000         63.0           5.0   \n",
      "5                 1.730767  ...  60.600000         59.0           3.0   \n",
      "\n",
      "   F_x__minimum  T_x__minimum  F_x__maximum  T_y__minimum  T_z__maximum  \\\n",
      "1          -1.0          -3.0           0.0          -1.0           0.0   \n",
      "2          -3.0         -10.0           0.0          -5.0           0.0   \n",
      "3          -1.0          -7.0           1.0          -5.0           0.0   \n",
      "4          -2.0         -15.0           1.0          -6.0           1.0   \n",
      "5          -2.0         -12.0           2.0          -5.0           1.0   \n",
      "\n",
      "   T_z__minimum  F_z__maximum  \n",
      "1           0.0          64.0  \n",
      "2          -1.0          70.0  \n",
      "3          -1.0          68.0  \n",
      "4          -1.0          70.0  \n",
      "5          -1.0          73.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "## Typical feature extraction\n",
    "selected_features = select_features(extracted_features,y)\n",
    "print(selected_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   F_z||variance__maximum  F_z||standard_deviation__maximum  \\\n",
      "1                3.000000                          1.732051   \n",
      "2               19.107438                          4.371206   \n",
      "3               22.250000                          4.716991   \n",
      "4               16.975207                          4.120098   \n",
      "5               44.750000                          6.689544   \n",
      "\n",
      "   T_y||variance__maximum  T_y||standard_deviation__maximum  \\\n",
      "1                0.231405                          0.481046   \n",
      "2                4.628099                          2.151302   \n",
      "3                2.975207                          1.724879   \n",
      "4                7.107438                          2.665978   \n",
      "5                4.561983                          2.135880   \n",
      "\n",
      "   F_z||variance__median  F_z||variance__sum_values  F_z||variance__mean  \\\n",
      "1               1.888430                   3.776860             1.888430   \n",
      "2              14.678719                  29.357438            14.678719   \n",
      "3              21.579545                  43.159091            21.579545   \n",
      "4               9.831353                  19.662707             9.831353   \n",
      "5              30.019628                  60.039256            30.019628   \n",
      "\n",
      "   F_x||standard_deviation__maximum  F_x||variance__maximum  \\\n",
      "1                          0.287480                0.082645   \n",
      "2                          1.083307                1.173554   \n",
      "3                          0.655555                0.429752   \n",
      "4                          1.067940                1.140496   \n",
      "5                          0.987525                0.975207   \n",
      "\n",
      "   F_x||variance__sum_values  ...  T_x||minimum__median  \\\n",
      "1                   0.082645  ...                  -3.0   \n",
      "2                   1.361054  ...                  -8.0   \n",
      "3                   0.429752  ...                  -7.0   \n",
      "4                   1.390496  ...                 -11.5   \n",
      "5                   0.975207  ...                 -10.5   \n",
      "\n",
      "   T_x||minimum__sum_values  T_x||minimum__mean  F_z||maximum__maximum  \\\n",
      "1                      -6.0                -3.0                   64.0   \n",
      "2                     -16.0                -8.0                   70.0   \n",
      "3                     -14.0                -7.0                   68.0   \n",
      "4                     -23.0               -11.5                   70.0   \n",
      "5                     -21.0               -10.5                   73.0   \n",
      "\n",
      "   F_x||maximum__mean  F_x||maximum__median  F_x||maximum__sum_values  \\\n",
      "1                -0.5                  -0.5                      -1.0   \n",
      "2                 0.0                   0.0                       0.0   \n",
      "3                 0.0                   0.0                       0.0   \n",
      "4                 0.5                   0.5                       1.0   \n",
      "5                 0.5                   0.5                       1.0   \n",
      "\n",
      "   T_z||maximum__mean  T_z||maximum__median  T_z||maximum__sum_values  \n",
      "1                 0.0                   0.0                       0.0  \n",
      "2                 0.0                   0.0                       0.0  \n",
      "3                 0.0                   0.0                       0.0  \n",
      "4                 0.5                   0.5                       1.0  \n",
      "5                 0.5                   0.5                       1.0  \n",
      "\n",
      "[5 rows x 184 columns]\n"
     ]
    }
   ],
   "source": [
    "selected_sub_features = select_features(extracted_sub_features,y)\n",
    "print(selected_sub_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x648 with 0 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15,9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given this new set of subfeatures - we can decompose this into the useful features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN the code with the smaller feature set\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new time series\n",
    "potentially move this to its own notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ad02abc6fd42dfd29d4ae95916e828d1e7d5f671b12d8bc3422f332d5494102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
